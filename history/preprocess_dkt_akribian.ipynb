{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"preprocess_dkt_akribian.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"-ILlxvOlONg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614071844742,"user_tz":-60,"elapsed":20483,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"20e70057-c151-435f-b06b-8031d172f03c"},"source":["import sys\n","import regex as re\n","import numpy as np\n","import io\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","import pickle\n","from numpy.linalg import norm\n","from scipy.spatial.distance import cosine\n","from sklearn.preprocessing import normalize\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense, Dropout, Lambda, TimeDistributed\n","from keras.layers import LSTM, Bidirectional, SimpleRNN, BatchNormalization, GRU\n","from keras.models import Model, load_model\n","from keras import regularizers\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.np_utils import to_categorical\n","from keras.activations import softmax\n","from copy import deepcopy\n","from google.colab import drive\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","from sklearn.ensemble import RandomForestClassifier\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","BASE_DIR = '/content/drive/My Drive/Colab Notebooks/thesis/'\n","INPUT_DIR = BASE_DIR + 'data/akribian/raw/'\n","OUTPUT_DIR = BASE_DIR + 'data/akribian/processed/dkt/'\n","#BASE_DIR = ''\n","\n","TIME_STEPS = 25\n","STEP_SHIFT = 1\n","BATCH_SIZE = 128\n","EPOCHS = 10\n","PADDING = 0\n","EMBEDDINGS_DIM = 5\n","NUMBER_OF_FEATURES = 3\n","VALIDATION_RATIO = 0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uxBy7HqMONg8"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"id":"i-ekVobzONg8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614071846871,"user_tz":-60,"elapsed":22606,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"c3e1621a-d5ed-4bbd-a586-4cbfdbc6f103"},"source":["# Remember that DataFrames are immutable\n","data = pd.read_csv(INPUT_DIR + \"rawdata.csv\")\n","columns_to_drop = ['StudentName', 'TrainingPlanId', 'TrainingPlanName',\n","       'LearningModuleId', 'LearningModuleName', 'LearningTaskId',\n","       'LearningTaskTitle', 'LearningSequenceId',\n","       'ExerciseId', 'ExerciseTitle', \n","       'SubmissionAnswers', 'SubmissionResponseTimes', 'ExerciseOutcome',\n","       'FinishedOn', 'ExerciseResultId',\n","       'LearningSequenceSessionId']\n","data = data.drop(columns_to_drop, axis='columns')\n","data.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['StudentId', 'LearningSequenceTitle', 'StudentSessionId',\n","       'SubmissionOutcomes', 'ExerciseResponseTime'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"ByWY_t78ONg-"},"source":["## Create title to index dictionary"]},{"cell_type":"code","metadata":{"id":"A5cmn73NONg_"},"source":["categories = ['PADDING'] + list(set(data['LearningSequenceTitle']))\n","category_to_embeddings = {}\n","\n","# Compress using random embeddings (compressed sensing)\n","for category in categories:\n","    random_array = np.random.normal(0.0, 1.0, EMBEDDINGS_DIM)\n","    category_to_embeddings[category] = random_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTyVdOlyQvqo"},"source":["embeddings_file = open(BASE_DIR + \"category_to_embeddings.pkl\", \"wb\")\r\n","pickle.dump(category_to_embeddings, embeddings_file)\r\n","embeddings_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DQ21W30IlCYS"},"source":["## Calculate z-score for response time "]},{"cell_type":"code","metadata":{"id":"EgjCoaAtlKRQ"},"source":["category_means = {}\r\n","category_stds = {}\r\n","\r\n","for category in categories:\r\n","  category_samples = data[ lambda x: x[\"LearningSequenceTitle\"] == category ]\r\n","\r\n","  mean = category_samples[\"ExerciseResponseTime\"].mean()\r\n","  if math.isnan(mean):\r\n","    mean = 0.\r\n","  category_means[category] = mean\r\n","\r\n","  std = category_samples[\"ExerciseResponseTime\"].std()\r\n","  if math.isnan(std):\r\n","    std = 1.\r\n","  if std == 0:\r\n","    std = 1.\r\n","  category_stds[category] = std  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OkY8tuNONg_"},"source":["\r\n","## Turn categories into embeddings"]},{"cell_type":"code","metadata":{"id":"_a9ZmCN5ONhA"},"source":["data[\"NumberOfAttempts\"] = \"\"\n","def process_row(row):\n","    # Calculate z-score for response time\n","    mean = category_means[row['LearningSequenceTitle']]\n","    std = category_stds[row['LearningSequenceTitle']]\n","    row['ExerciseResponseTime'] = ( row['ExerciseResponseTime'] - mean ) / std \n","\n","    # Turn category into an embedding\n","    row['LearningSequenceTitle'] = category_to_embeddings[row['LearningSequenceTitle']]\n","\n","    # Extract number of attempts\n","    # 1 means first try, 2 means 2 tries, 3 means 3 or more\n","    number_of_attempts = 1 + row['SubmissionOutcomes'].count(',')\n","\n","    if number_of_attempts > 3:\n","      number_of_attempts = 3\n","\n","    row['NumberOfAttempts'] = number_of_attempts\n","\n","    # Use only first outcome\n","    row['SubmissionOutcomes'] = int(row['SubmissionOutcomes'][0])\n","    return row\n","data = data.apply(process_row, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"4lou4u2WONhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614071858918,"user_tz":-60,"elapsed":34643,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"b980810e-a1be-4e70-e9d2-9bffa02478b7"},"source":["series = data.drop(['StudentSessionId'],axis='columns').groupby(['StudentId']).agg({lambda x: list(x)})\r\n","print(\"Number of users: %i\" % len(series))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of users: 112\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"94ues2RtONhA"},"source":["series_np = series.to_numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rI67DrdHONhB"},"source":["def convert_series_to_data(series):\n","    # Extract exercises\n","    exercises = np.array(series[0])\n","    exercises_shifted = np.roll(exercises, -1, axis=0)\n","    # Set the embeddings of the last exercise to the 'padding' embeddings\n","    exercises_shifted[-1,:] = category_to_embeddings['PADDING']\n","\n","\n","    # Extract answers\n","    answers = np.array(series[1])\n","\n","    # Prepare future answers vector (used as label)\n","    # Answer labels are {0, 1} which corresponds to probability of correctness\n","    answers_shifted = np.roll(answers, -1)\n","    answers_shifted[answers_shifted > 1.0] = 1.0\n","    answers_shifted = 1.0 - answers_shifted\n","\n","\n","    # Answer features should be {1, 2, 3} with 0 reserved for padding\n","    answers += 1\n","    response_times = np.array(series[2])\n","    number_of_attempts = np.array(series[3])\n","        \n","    # Pad the sequences\n","    pad_length = TIME_STEPS - len(exercises)\n","    if (pad_length < 0): pad_length = 0\n","\n","    padded_answers_shifted = np.pad(answers_shifted, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","\n","    # Reshape arrays so they can be concatenated\n","    answers = answers.reshape((len(answers), 1))\n","    response_times = response_times.reshape((len(response_times), 1))\n","    number_of_attempts = number_of_attempts.reshape((len(number_of_attempts), 1))\n","\n","    # Concatenate features vector\n","    features = np.concatenate((exercises, exercises_shifted, answers, response_times, number_of_attempts), axis=1)\n","    padded_features = np.pad(features, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","    padded_features = padded_features[:, pad_length:]\n","\n","    labels = padded_answers_shifted\n","    \n","    # Drop entries to the left so we have a discrete number of shifts\n","    number_of_samples = len(padded_features)\n","    entries_to_drop = (number_of_samples - TIME_STEPS) % STEP_SHIFT\n","    features = padded_features[entries_to_drop:, :]\n","    labels = labels[entries_to_drop:]\n","    \n","    number_of_sequences = int(math.floor((number_of_samples - TIME_STEPS) / STEP_SHIFT + 1))\n","    \n","    final_features = np.ndarray((number_of_sequences, TIME_STEPS, EMBEDDINGS_DIM * 2 + NUMBER_OF_FEATURES))\n","    final_labels = np.ndarray((number_of_sequences, 1))\n","    \n","    for i in range(number_of_sequences):\n","        final_features[i, :, :] = features[i * STEP_SHIFT : i * STEP_SHIFT + TIME_STEPS, :]\n","        final_labels[i, :] = labels[TIME_STEPS - 1 + i * STEP_SHIFT]\n","\n","    return final_features, final_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5fDLGkRONhB"},"source":["samples = len(series_np)\n","inputs = None\n","outputs = None\n","for idx, series in enumerate(series_np):\n","    input_array, output_array = convert_series_to_data(series)\n","    if idx == 0: \n","        inputs = input_array\n","        outputs = output_array\n","        continue\n","    inputs = np.append(inputs, input_array, axis=0)\n","    outputs = np.append(outputs, output_array)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVeDXLQ9ONhD"},"source":["with open(OUTPUT_DIR + 'inputs.npy','wb') as file:\n","    np.save(file, inputs)\n","with open(OUTPUT_DIR + 'outputs.npy','wb') as file:\n","    np.save(file, outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dzwBCJjyy-K","executionInfo":{"status":"ok","timestamp":1614071862935,"user_tz":-60,"elapsed":38651,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"e416a82b-243c-4675-bea4-b5d6bd1df0b7"},"source":["np.isnan(inputs).any()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"OLXTL7wy0j36"},"source":[""],"execution_count":null,"outputs":[]}]}