{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"preprocess_with_embeddings.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ILlxvOlONg0","executionInfo":{"status":"ok","timestamp":1611742342919,"user_tz":-60,"elapsed":1882,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"75c94dfb-8ded-4fe9-8526-13b4daeba5c8"},"source":["import sys\n","import regex as re\n","import numpy as np\n","import io\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","from numpy.linalg import norm\n","from scipy.spatial.distance import cosine\n","from sklearn.preprocessing import normalize\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense, Dropout, Lambda, TimeDistributed\n","from keras.layers import LSTM, Bidirectional, SimpleRNN, BatchNormalization, GRU\n","from keras.models import Model, load_model\n","from keras import regularizers\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.np_utils import to_categorical\n","from keras.activations import softmax\n","from copy import deepcopy\n","from google.colab import drive\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","from sklearn.ensemble import RandomForestClassifier\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","BASE_DIR = '/content/drive/My Drive/Colab Notebooks/thesis/'\n","#BASE_DIR = ''\n","\n","TIME_STEPS = 25\n","STEP_SHIFT = 1\n","BATCH_SIZE = 128\n","EPOCHS = 10\n","PADDING = 0\n","EMBEDDINGS_DIM = 5\n","VALIDATION_RATIO = 0.3"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uxBy7HqMONg8"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-ekVobzONg8","executionInfo":{"status":"ok","timestamp":1611742343564,"user_tz":-60,"elapsed":2522,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"8283c705-aea3-4123-d1ac-410e4a4c9662"},"source":["# Remember that DataFrames are immutable\n","data = pd.read_csv(BASE_DIR + \"rawdata.csv\")\n","columns_to_drop = ['StudentName', 'TrainingPlanId', 'TrainingPlanName',\n","       'LearningModuleId', 'LearningModuleName', 'LearningTaskId',\n","       'LearningTaskTitle', 'LearningSequenceId',\n","       'ExerciseId', 'ExerciseTitle', \n","       'SubmissionAnswers', 'SubmissionResponseTimes', 'ExerciseOutcome',\n","       'ExerciseResponseTime', 'FinishedOn', 'ExerciseResultId',\n","       'LearningSequenceSessionId']\n","data = data.drop(columns_to_drop, axis='columns')\n","data.columns"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['StudentId', 'LearningSequenceTitle', 'StudentSessionId',\n","       'SubmissionOutcomes'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"ByWY_t78ONg-"},"source":["## Create title to index dictionary"]},{"cell_type":"code","metadata":{"id":"A5cmn73NONg_","executionInfo":{"status":"ok","timestamp":1611742343565,"user_tz":-60,"elapsed":2519,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["categories = ['PADDING'] + list(set(data['LearningSequenceTitle']))\n","category_to_embeddings = {}\n","\n","# Compress using random embeddings (compressed sensing)\n","for category in categories:\n","    random_array = np.random.normal(0.0, 1.0, EMBEDDINGS_DIM)\n","    category_to_embeddings[category] = random_array\n"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OkY8tuNONg_"},"source":["## Turn categories into embeddings"]},{"cell_type":"code","metadata":{"id":"_a9ZmCN5ONhA","executionInfo":{"status":"ok","timestamp":1611742349948,"user_tz":-60,"elapsed":8901,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["def process_row(row):\n","    # Turn category into an embedding\n","    row['LearningSequenceTitle'] = category_to_embeddings[row['LearningSequenceTitle']]\n","    # Use only first outcome\n","    row['SubmissionOutcomes'] = int(row['SubmissionOutcomes'][0])\n","    return row\n","data = data.apply(process_row, axis=1)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"4lou4u2WONhA","executionInfo":{"status":"ok","timestamp":1611742349950,"user_tz":-60,"elapsed":8901,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["series = data.drop(['StudentSessionId'],axis='columns').groupby(['StudentId']).agg({lambda x: list(x)})"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"94ues2RtONhA","executionInfo":{"status":"ok","timestamp":1611742349951,"user_tz":-60,"elapsed":8900,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["series_np = series.to_numpy()"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"rI67DrdHONhB","executionInfo":{"status":"ok","timestamp":1611742349952,"user_tz":-60,"elapsed":8897,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["def convert_series_to_data(series):\n","    # Extract exercises\n","    exercises = np.array(series[0])\n","    exercises_shifted = np.roll(exercises, -1, axis=0)\n","    # Set the embeddings of the last exercise to the 'padding' embeddings\n","    exercises_shifted[-1,:] = category_to_embeddings['PADDING']\n","\n","\n","    # Extract answers\n","    # Answer features are {1, 2, 3} with 0 reserved for padding\n","    # Answer labels are {0, 1} which corresponds to probability of correctness\n","    answers = np.array(series[1])\n","    answers_shifted = np.roll(answers, -1)\n","    answers_shifted[answers_shifted > 1.0] = 1.0\n","    answers_shifted = 1.0 - answers_shifted\n","    answers += 1\n","        \n","    # Pad the sequences\n","    pad_length = TIME_STEPS - len(exercises)\n","    if (pad_length < 0): pad_length = 0\n","\n","    padded_exercises = np.pad(exercises, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","    padded_exercises = padded_exercises[:, pad_length:]\n","    padded_exercises_shifted = np.pad(exercises_shifted, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","    padded_exercises_shifted = padded_exercises_shifted[:, pad_length:]\n","\n","    # Create output array, and pad if too short\n","    padded_answers = np.pad(answers, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","    padded_answers_shifted = np.pad(answers_shifted, (pad_length, 0), 'constant', constant_values=(PADDING, PADDING))\n","\n","    padded_answers = padded_answers.reshape((len(padded_answers), 1))\n","\n","    # Concatenate features vector\n","    features = np.concatenate((padded_exercises, padded_exercises_shifted, padded_answers), axis=1)\n","    labels = padded_answers_shifted\n","    \n","    # Drop entries to the left so we have a discrete number of shifts\n","    number_of_samples = len(padded_exercises)\n","    entries_to_drop = (number_of_samples - TIME_STEPS) % STEP_SHIFT\n","    features = features[entries_to_drop:, :]\n","    labels = labels[entries_to_drop:]\n","    \n","    number_of_sequences = int(math.floor((number_of_samples - TIME_STEPS) / STEP_SHIFT + 1))\n","    \n","    final_features = np.ndarray((number_of_sequences, TIME_STEPS, EMBEDDINGS_DIM * 2 + 1))\n","    final_labels = np.ndarray((number_of_sequences, 1))\n","    \n","    for i in range(number_of_sequences):\n","        final_features[i, :, :] = features[i * STEP_SHIFT : i * STEP_SHIFT + TIME_STEPS, :]\n","        final_labels[i, :] = labels[TIME_STEPS - 1 + i * STEP_SHIFT]\n","\n","    return final_features, final_labels"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5fDLGkRONhB","executionInfo":{"status":"ok","timestamp":1611742353112,"user_tz":-60,"elapsed":12053,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["samples = len(series_np)\n","inputs = None\n","outputs = None\n","for idx, series in enumerate(series_np):\n","    input_array, output_array = convert_series_to_data(series)\n","    if idx == 0: \n","        inputs = input_array\n","        outputs = output_array\n","        continue\n","    inputs = np.append(inputs, input_array, axis=0)\n","    outputs = np.append(outputs, output_array)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVeDXLQ9ONhD","executionInfo":{"status":"ok","timestamp":1611742353582,"user_tz":-60,"elapsed":12520,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["with open(BASE_DIR + 'inputs.npy','wb') as file:\n","    np.save(file, inputs)\n","with open(BASE_DIR + 'outputs.npy','wb') as file:\n","    np.save(file, outputs)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ff5VDqJxO39p","executionInfo":{"status":"ok","timestamp":1611742353583,"user_tz":-60,"elapsed":12518,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":[""],"execution_count":53,"outputs":[]}]}