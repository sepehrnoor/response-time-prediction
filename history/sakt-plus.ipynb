{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sakt-plus.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mS0jKfc49ldg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613996165030,"user_tz":-60,"elapsed":22114,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"7dc1565b-7abd-4494-cb72-167d0fe65731"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.modules import Linear\n","from torch.nn.parameter import Parameter\n","from torch.nn.init import xavier_uniform_\n","from torch.nn.init import constant_\n","from torch.nn.init import xavier_normal_\n","from typing import Optional, Tuple\n","import numpy as np\n","import sys\n","import regex as re\n","import io\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import pandas as pd\n","import math\n","import tensorflow as tf\n","import h5py\n","import copy\n","from torch.utils.data import DataLoader, Dataset\n","from numpy.linalg import norm\n","from scipy.spatial.distance import cosine\n","from scipy.special import softmax\n","from copy import deepcopy\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","from sklearn.metrics import roc_auc_score\n","\n","LOCAL = False\n","BASE_DIR = '../'\n","\n","if not LOCAL:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    BASE_DIR = '/content/drive/My Drive/Colab Notebooks/thesis/'\n","\n","sys.path.append(BASE_DIR + 'lib')\n","sys.path.append(BASE_DIR + 'config')\n","from preprocessing import process_sakt, save_h5\n","import dataset_parameters as params\n","\n","# DATASET = 'akribian'\n","DATASET = 'assistments_2009'\n","# DATASET = 'junyi_academy'\n","# DATASET = 'ednet'\n","\n","INPUT_DIR = BASE_DIR + 'data/' + DATASET + '/raw/'\n","OUTPUT_DIR = BASE_DIR + 'data/' + DATASET + '/processed/sakt/'\n","\n","TIME_STEPS = params.time_steps_dict[DATASET]\n","\n","IN_DATA_PATH = BASE_DIR + 'data/' + DATASET + '/processed/sakt/' \n","MODEL_PATH = BASE_DIR + 'models/sakt/' \n","\n","# Training parameters\n","BATCH_SIZE = 64\n","LATENT_DIM = 256 # latent dimension\n","PADDING = 0\n","SHUFFLE = True\n","TIME_STEPS = params.time_steps_dict[DATASET]\n","#EPOCHS = params.epochs_dict[DATASET]\n","EPOCHS = 1\n","NUMBER_OF_EXERCISES = params.exercise_dict[DATASET]\n","ROWS_PER_READ = 1000000\n","\n","EARLY_STOPPING_TOLERANCE = 3\n","\n","# File paths\n","INPUT_PATH = IN_DATA_PATH + \"processed.h5\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VWkff08XDl6t"},"source":["## Self attention module"]},{"cell_type":"code","metadata":{"id":"SY1ii18UPw2Q","executionInfo":{"status":"ok","timestamp":1613996165031,"user_tz":-60,"elapsed":22109,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["def future_mask(seq_length):\r\n","    future_mask = np.triu(np.ones((1, seq_length, seq_length)), k=1).astype('bool')\r\n","    return torch.from_numpy(future_mask)\r\n","\r\n","\r\n","def clone(module, num):\r\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(num)])\r\n","\r\n","# def relative_attention(query, key, value, rel, l1, l2, pos_key_embeds, pos_value_embeds, mask=None, dropout=None):\r\n","def relative_attention(query, key, value, mask=None, dropout=None):\r\n","    \"\"\"Compute scaled dot product attention with relative position embeddings.\r\n","    (https://arxiv.org/pdf/1803.02155.pdf)\r\n","    \"\"\"\r\n","#    assert pos_key_embeds.num_embeddings == pos_value_embeds.num_embeddings\r\n","\r\n","    print(\"query\")\r\n","    print(query.shape)\r\n","    print(\"key\")\r\n","    print(key.shape)    \r\n","    print(\"key transposed\")\r\n","    print(key.transpose(-2, -1).shape)    \r\n","    scores = torch.matmul(query, key.transpose(-2, -1))\r\n","    print(\"scores\")\r\n","    print(scores.shape)    \r\n","\r\n","    # idxs = torch.arange(scores.size(-1))\r\n","    # if query.is_cuda:\r\n","    #     idxs = idxs.cuda()\r\n","    # idxs = idxs.view(-1, 1) - idxs.view(1, -1)\r\n","    # idxs = torch.clamp(idxs, 0, pos_key_embeds.num_embeddings - 1)\r\n","\r\n","    # pos_key = pos_key_embeds(idxs).transpose(-2, -1)\r\n","    # pos_scores = torch.matmul(query.unsqueeze(-2), pos_key)\r\n","    scores = scores.unsqueeze(-2)\r\n","    scores = scores / math.sqrt(query.size(-1))\r\n","\r\n","    # pos_value = pos_value_embeds(idxs)\r\n","    value = value.unsqueeze(-3)\r\n","\r\n","    print(\"scores\")\r\n","    print(scores.shape)\r\n","    print(\"mask\")\r\n","    print(mask.shape)\r\n","    if mask is not None:\r\n","        scores = scores.masked_fill(mask.unsqueeze(-2), -1e9)\r\n","    prob_attn = F.softmax(scores, dim=-1)\r\n","    if dropout is not None:\r\n","        prob_attn = dropout(prob_attn)\r\n","\r\n","    output = torch.matmul(prob_attn, value).unsqueeze(-2)\r\n","    prob_attn = prob_attn.unsqueeze(-2)\r\n","    return output, prob_attn"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MkblaQ7DoSu","executionInfo":{"status":"ok","timestamp":1613996165786,"user_tz":-60,"elapsed":22860,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["class MultiHeadedAttention(nn.Module):\r\n","    def __init__(self, head_size, num_heads, drop_prob):\r\n","        super(MultiHeadedAttention, self).__init__()\r\n","        self.head_size = head_size\r\n","        self.num_heads = num_heads\r\n","        # W^Q, W^K, W^V\r\n","        self.linear_layers = clone(nn.Linear(head_size, head_size), 3)\r\n","        self.dropout = nn.Dropout(p=drop_prob)\r\n","\r\n","    def forward(self, query, key, value, mask=None):\r\n","        batch_size = query.shape[1]\r\n","        seq_length = query.shape[0]\r\n","        print(\"batch size %i time steps %i\" % (batch_size, seq_length))\r\n","        print(\"query looks like this\")\r\n","        print(query.shape)\r\n","        print(query)\r\n","\r\n","        # Apply mask to all heads\r\n","        if mask is not None:\r\n","            mask = mask.unsqueeze(1)\r\n","\r\n","        # Project inputs\r\n","        #rel = rel.unsqueeze(1).repeat(1,self.num_heads,1,1)\r\n","        #timestamp = timestamp.unsqueeze(1).repeat(1,self.num_heads,1,1)\r\n","        query, key, value = [l(x).view(batch_size, seq_length, self.num_heads, self.head_size).transpose(1, 2)\r\n","                             for l, x in zip(self.linear_layers, (query, key, value))]\r\n","\r\n","        # Apply attention\r\n","        out, self.prob_attn = relative_attention(query, key, value, mask, self.dropout)\r\n","\r\n","        out = out.transpose(1, 2).contiguous().view(batch_size, seq_length, self.head_size)\r\n","        return out, self.prob_attn"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYuTj4YDA46z"},"source":["# Model class"]},{"cell_type":"code","metadata":{"id":"hRpSJE5X9o5X","executionInfo":{"status":"ok","timestamp":1613996165787,"user_tz":-60,"elapsed":22859,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["class sakt(nn.Module):  \n","    def __init__(self , ex_total , seq_len, dim, heads, dout ):\n","        super(sakt, self).__init__()\n","        self.seq_len = seq_len\n","        self.dim = dim\n","        embedding_dim = dim\n","\n","        self.embd_in = nn.Embedding( 2*ex_total+1, embedding_dim  = embedding_dim ).cuda()         # Interaction embedding\n","        self.embd_ex = nn.Embedding( ex_total+1 , embedding_dim = embedding_dim ).cuda()       # Excercise embedding\n","        self.embd_pos = nn.Embedding( seq_len , embedding_dim = embedding_dim ).cuda()\n","\n","        self.linear = nn.ModuleList( [nn.Linear(in_features= embedding_dim , out_features= dim ).cuda() for x in range(3)] ).cuda()   # Linear projection for each embedding\n","        self.attn = MultiHeadedAttention(head_size= dim , num_heads= heads, drop_prob= dout ).cuda()\n","        self.ffn = nn.ModuleList([nn.Linear(in_features= dim , out_features=dim, bias= True).cuda() for x in range(2)]).cuda()  # feed forward layers post attention\n","\n","        self.linear_out = nn.Linear(in_features= dim , out_features= 1 , bias=True).cuda()\n","        self.layer_norm1 = nn.LayerNorm( dim ).cuda()\n","        self.layer_norm2 = nn.LayerNorm( dim ).cuda()                           # output with correctnness prediction \n","        self.drop = nn.Dropout(dout).cuda()\n","\n","    def forward( self , input_in , input_ex):\n","\n","        ## positional embedding\n","        pos_in = self.embd_pos( torch.arange(self.seq_len).unsqueeze(0) )         #making a tensor of 12 numbers, .unsqueeze(0) for converting to 2d, so as to get a 3d output #print('pos embd' , pos_in.shape)\n","\n","        ## get the interaction embedding output\n","        out_in = self.embd_in( input_in )                         # (b, n) --> (b,n,d)\n","        out_in = out_in + pos_in\n","\n","        ## split the interaction embeding into v and k ( needs to verify if it is slpited or not)\n","        value_in = out_in\n","        key_in   = out_in                                         #print('v,k ', value_in.shape)\n","        \n","        ## get the excercise embedding output\n","        query_ex = self.embd_ex( input_ex )                       # (b,n) --> (b,n,d) #print(query_ex.shape)\n","        \n","        ## Linearly project all the embedings\n","        value_in = self.linear[0](value_in).permute(1,0,2)        # (b,n,d) --> (n,b,d)\n","        key_in = self.linear[1](key_in).permute(1,0,2)\n","        query_ex =  self.linear[2](query_ex).permute(1,0,2)\n","\n","        ## pass through multihead attention\n","                       #forward(query, key, value, rel, l1, l2, timestamp, encode_pos, pos_key_embeds, pos_value_embeds, mask=None):\n","        atn_out , _ = self.attn(query_ex , key_in, value_in, mask= torch.from_numpy( np.triu(np.ones((self.seq_len ,self.seq_len)), k=1).astype('bool')).cuda() )      # lower triangular mask, bool, torch    (n,b,d)\n","        atn_out = query_ex + atn_out                                  # Residual connection ; added excercise embd as residual because previous ex may have imp info, suggested in paper.\n","        atn_out = self.layer_norm1( atn_out )                          # Layer norm                        #print('atn',atn_out.shape) #n,b,d = atn_out.shape\n","\n","        #take batch on first axis \n","        atn_out = atn_out.permute(1,0,2)                              #  (n,b,d) --> (b,n,d)\n","        \n","        ## FFN 2 layers\n","        ffn_out = self.drop(self.ffn[1]( nn.ReLU()( self.ffn[0]( atn_out ) )))   # (n,b,d) -->    .view([n*b ,d]) is not needed according to the kaggle implementation\n","        ffn_out = self.layer_norm2( ffn_out + atn_out )                # Layer norm and Residual connection\n","\n","        ## sigmoid\n","        ffn_out = torch.sigmoid(self.linear_out( ffn_out )  )\n","\n","        return ffn_out\n","          \n","def randomdata():\n","    input_in = torch.randint( 0 , 49 ,(64 , 25) )\n","    return input_in, input_in\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDZ7Ydz2xgyu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613996165787,"user_tz":-60,"elapsed":22856,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"57910976-ff4d-4ff5-8964-48082b541875"},"source":["print(\"CUDA available: %i\" % torch.cuda.is_available())\n","cuda = torch.device(\"cuda:0\")\n","torch.set_default_tensor_type('torch.cuda.FloatTensor')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["CUDA available: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hb_0zPXOA47C"},"source":["# Model training"]},{"cell_type":"code","metadata":{"id":"nTrGRcF99q_D","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1613996183437,"user_tz":-60,"elapsed":40503,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}},"outputId":"3a4c0dc3-46c4-456f-a847-757885b30c3e"},"source":["## Training the model\n","print_freq = 10\n","graph_freq = 10\n","\n","model = sakt( ex_total= NUMBER_OF_EXERCISES, seq_len= TIME_STEPS, dim= LATENT_DIM, heads= 8, dout= 0.2 )\n","model = model.cuda()\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","losses_history = []\n","\n","val_aucs = []\n","\n","previous_auc = 0.0\n","\n","no_improvement_streak = 0\n","best_auc = 0.0\n","\n","h5_file = h5py.File(INPUT_PATH,'r')\n","\n","# labels_val = torch.from_numpy(h5_file['labels_val'][:]).flatten()\n","\n","number_of_train_windows = h5_file['exercises_val'].shape[0]\n","number_of_val_windows = h5_file['exercises_val'].shape[0]\n","\n","for epoch in range(EPOCHS):\n","  print(\"Epoch %i\" % (epoch+1))\n","  total_loss_print = 0.0\n","  total_loss_graph = 0.0\n","\n","  for read_index in range(0, number_of_train_windows, ROWS_PER_READ):\n","\n","    exercises_train = h5_file['exercises_train'][read_index:read_index+ROWS_PER_READ]\n","    interactions_train = h5_file['interactions_train'][read_index:read_index+ROWS_PER_READ]\n","    labels_train = h5_file['labels_train'][read_index:read_index+ROWS_PER_READ]\n","\n","    for idx in range(0, len(exercises_train), BATCH_SIZE):\n","      # Retrieve data\n","      ex_samples = torch.from_numpy(exercises_train[idx:idx + BATCH_SIZE]).long().cuda()\n","      in_samples = torch.from_numpy(interactions_train[idx:idx + BATCH_SIZE]).long().cuda()\n","      label = torch.from_numpy(labels_train[idx:idx + BATCH_SIZE]).long().cuda()\n","      label = torch.unsqueeze(label, 2)\n","\n","      # Reset optimizer\n","      optimizer.zero_grad()\n","\n","      # Predict\n","      out = model(in_samples, ex_samples)\n","\n","      # Calculate loss \n","      loss = criterion(out, label.float())\n","      total_loss_print += loss.item()\n","      total_loss_graph += loss.item()\n","\n","      # Optimize\n","      loss.backward()\n","      optimizer.step()\n","\n","      idx_discrete = int(idx / BATCH_SIZE)\n","\n","      # Print status\n","      if (idx_discrete % print_freq == print_freq - 1):\n","        avg_loss = total_loss_print/print_freq\n","        sys.stdout.write(\"\\rIteration %i, avg loss %f\" % (idx+1, avg_loss))\n","        sys.stdout.flush()\n","        total_loss_print = 0.0\n","\n","      # Append to graph\n","      if (idx_discrete % graph_freq == graph_freq - 1):\n","        avg_loss = total_loss_graph/graph_freq\n","        losses_history.append(avg_loss)\n","        total_loss_graph = 0.0\n","          \n","  # Validation step\n","  # Set evaluation mode\n","  outs_preds = np.array([])\n","  model.eval()\n","  # Turn off grad calculation\n","  with torch.no_grad():\n","    # Iterate through val data\n","    for read_index in range(0, number_of_val_windows, ROWS_PER_READ):\n","      exercises_val = h5_file['exercises_val'][read_index:read_index+ROWS_PER_READ]\n","      interactions_val = h5_file['interactions_val'][read_index:read_index+ROWS_PER_READ]\n","      for idx in range(0, len(exercises_val), BATCH_SIZE):\n","        in_samples = torch.from_numpy(interactions_val[idx:idx + BATCH_SIZE]).long().cuda()\n","        ex_samples = torch.from_numpy(exercises_val[idx:idx + BATCH_SIZE]).long().cuda()\n","        outs_pred = model(in_samples, ex_samples)\n","        outs_pred_flattened = torch.flatten(outs_pred)\n","        outs_pred_flattened = outs_pred_flattened.cpu().detach().numpy()\n","        outs_preds = np.append(outs_preds, outs_pred_flattened)\n","  # Revert to training mode\n","  model.train()\n","\n","  labels_val = h5_file['labels_val'][:].flatten()\n","  auc_score = roc_auc_score(labels_val, outs_preds)\n","  val_aucs.append(auc_score)\n","  print(\"\\nValidation AUC: %f\" % auc_score)\n","  auc_diff = auc_score - previous_auc\n","  if epoch != 0:\n","    print(\"AUC difference: %f\" % auc_diff)\n","\n","  if auc_score < best_auc:\n","    no_improvement_streak += 1\n","  else:\n","    no_improvement_streak = 0\n","    best_auc = auc_score\n","    torch.save(model.state_dict(), MODEL_PATH + DATASET + \".torch\")\n","    print(\"Model saved\")\n","\n","  if no_improvement_streak == EARLY_STOPPING_TOLERANCE:\n","    break\n","\n","  previous_auc = auc_score\n","\n","h5_file.close()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1\n","batch size 64 time steps 120\n","query looks like this\n","torch.Size([120, 64, 256])\n","tensor([[[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.2487,  0.2518,  0.2651,  ..., -0.3347, -0.2110,  0.6179],\n","         [-0.6471,  0.7694,  0.2249,  ..., -0.0469, -0.0738, -1.1035],\n","         ...,\n","         [-0.6471,  0.7694,  0.2249,  ..., -0.0469, -0.0738, -1.1035],\n","         [ 0.0825, -0.1178,  0.5553,  ...,  0.3893,  0.3784,  0.3777],\n","         [-0.3111,  0.0278, -1.1743,  ..., -0.0267,  0.0021,  0.8743]],\n","\n","        [[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.2487,  0.2518,  0.2651,  ..., -0.3347, -0.2110,  0.6179],\n","         [-0.6471,  0.7694,  0.2249,  ..., -0.0469, -0.0738, -1.1035],\n","         ...,\n","         [-0.6261, -0.7074, -0.4572,  ..., -0.0521,  0.6354, -0.2275],\n","         [ 0.0825, -0.1178,  0.5553,  ...,  0.3893,  0.3784,  0.3777],\n","         [-0.3111,  0.0278, -1.1743,  ..., -0.0267,  0.0021,  0.8743]],\n","\n","        [[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.2487,  0.2518,  0.2651,  ..., -0.3347, -0.2110,  0.6179],\n","         [-0.6471,  0.7694,  0.2249,  ..., -0.0469, -0.0738, -1.1035],\n","         ...,\n","         [-0.6261, -0.7074, -0.4572,  ..., -0.0521,  0.6354, -0.2275],\n","         [ 0.0825, -0.1178,  0.5553,  ...,  0.3893,  0.3784,  0.3777],\n","         [-0.3111,  0.0278, -1.1743,  ..., -0.0267,  0.0021,  0.8743]],\n","\n","        ...,\n","\n","        [[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.5816, -0.1156,  0.0672,  ...,  0.5350,  0.5661,  0.1023],\n","         [ 0.4699,  0.1755, -0.7981,  ..., -0.0146,  0.2072,  0.6315],\n","         ...,\n","         [ 0.0833, -0.6162, -0.0154,  ..., -0.5463,  0.7116, -0.6746],\n","         [-0.0369,  1.0283,  0.4398,  ...,  0.1848, -0.3832, -1.0225],\n","         [-0.1082,  1.2532, -0.2855,  ..., -0.3194,  0.8201,  0.7184]],\n","\n","        [[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.5816, -0.1156,  0.0672,  ...,  0.5350,  0.5661,  0.1023],\n","         [-0.4530,  0.4346, -0.7662,  ..., -0.9232,  0.7960, -0.4546],\n","         ...,\n","         [ 0.0833, -0.6162, -0.0154,  ..., -0.5463,  0.7116, -0.6746],\n","         [-0.0369,  1.0283,  0.4398,  ...,  0.1848, -0.3832, -1.0225],\n","         [-0.1082,  1.2532, -0.2855,  ..., -0.3194,  0.8201,  0.7184]],\n","\n","        [[ 0.6667, -0.0163, -0.4275,  ..., -0.4787,  0.3237,  0.0768],\n","         [-0.5816, -0.1156,  0.0672,  ...,  0.5350,  0.5661,  0.1023],\n","         [-0.1796, -0.6516, -0.9876,  ..., -0.0636,  0.5644, -0.1806],\n","         ...,\n","         [-0.1330, -0.2009,  1.0614,  ...,  0.4663, -0.2066, -1.0076],\n","         [-0.0369,  1.0283,  0.4398,  ...,  0.1848, -0.3832, -1.0225],\n","         [ 0.2022, -0.4092,  0.7150,  ..., -0.4155,  0.5898, -1.2043]]],\n","       grad_fn=<PermuteBackward>)\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e1b0ad129fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-be6c1dbe726f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_in, input_ex)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m## pass through multihead attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                        \u001b[0;31m#forward(query, key, value, rel, l1, l2, timestamp, encode_pos, pos_key_embeds, pos_value_embeds, mask=None):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0matn_out\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_ex\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkey_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m      \u001b[0;31m# lower triangular mask, bool, torch    (n,b,d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0matn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_ex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0matn_out\u001b[0m                                  \u001b[0;31m# Residual connection ; added excercise embd as residual because previous ex may have imp info, suggested in paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0matn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0matn_out\u001b[0m \u001b[0;34m)\u001b[0m                          \u001b[0;31m# Layer norm                        #print('atn',atn_out.shape) #n,b,d = atn_out.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-cb13a08f10ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#timestamp = timestamp.unsqueeze(1).repeat(1,self.num_heads,1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         query, key, value = [l(x).view(batch_size, seq_length, self.num_heads, self.head_size).transpose(1, 2)\n\u001b[0;32m---> 26\u001b[0;31m                              for l, x in zip(self.linear_layers, (query, key, value))]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Apply attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-cb13a08f10ee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#timestamp = timestamp.unsqueeze(1).repeat(1,self.num_heads,1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         query, key, value = [l(x).view(batch_size, seq_length, self.num_heads, self.head_size).transpose(1, 2)\n\u001b[0;32m---> 26\u001b[0;31m                              for l, x in zip(self.linear_layers, (query, key, value))]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Apply attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 120, 8, 256]' is invalid for input of size 1966080"]}]},{"cell_type":"code","metadata":{"id":"TaZ_Whg0SeO4","executionInfo":{"status":"aborted","timestamp":1613996183434,"user_tz":-60,"elapsed":40496,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["plt.figure(1)\r\n","plt.plot(losses_history)\r\n","\r\n","plt.figure(2)\r\n","plt.plot(val_aucs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9crKvJEZYsrw","executionInfo":{"status":"aborted","timestamp":1613996183435,"user_tz":-60,"elapsed":40494,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["outs_preds = np.array([])\n","\n","# predict iteratively in batches to avoid overloading VRAM\n","h5_file = h5py.File(INPUT_PATH,'r')\n","number_of_test_windows = h5_file['exercises_test'].shape[0]\n","for read_index in range(0, number_of_test_windows, ROWS_PER_READ):\n","  exercises_test = h5_file['exercises_test'][read_index:read_index+ROWS_PER_READ]\n","  interactions_test = h5_file['interactions_test'][read_index:read_index+ROWS_PER_READ]\n","  for idx in range(0, len(exercises_test), BATCH_SIZE):\n","    ex_samples = torch.from_numpy(exercises_test[idx:idx + BATCH_SIZE]).long().cuda()\n","    in_samples = torch.from_numpy(interactions_test[idx:idx + BATCH_SIZE]).long().cuda()\n","    outs_pred = model(in_samples, ex_samples)\n","    outs_pred = outs_pred.flatten().cpu().detach().numpy()\n","    outs_preds = np.append(outs_preds, outs_pred)\n","outs_test_flattened = h5_file['labels_test'][:].flatten()\n","h5_file.close()\n","print(outs_preds.shape)\n","print(outs_test_flattened.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dGYVkS2Vgds","executionInfo":{"status":"aborted","timestamp":1613996183436,"user_tz":-60,"elapsed":40493,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["fpr_keras, tpr_keras, thresholds_keras = roc_curve(outs_test_flattened, outs_preds)\n","auc_keras = roc_auc_score(outs_test_flattened, outs_preds)\n","#auc_keras = auc(fpr_keras, tpr_keras)\n","\n","plt.figure(3, figsize=(12,8), dpi=80)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot(fpr_keras, tpr_keras, label='ROC (area = {:.3f})'.format(auc_keras))\n","plt.xlabel('False positive rate')\n","plt.ylabel('True positive rate')\n","plt.title('ROC curve')\n","plt.legend(loc='best')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8rOHInbOeKp","executionInfo":{"status":"aborted","timestamp":1613996183436,"user_tz":-60,"elapsed":40491,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":["h5_file = h5py.File(INPUT_PATH,'r')\n","\n","\n","index = 80\n","img_width = TIME_STEPS\n","max_width = 50\n","\n","ex_samples = h5_file['exercises_test'][index]\n","ground_truth = outs_test_flattened[index*TIME_STEPS:(index+1)*TIME_STEPS]\n","pred = outs_preds[index*TIME_STEPS:(index+1)*TIME_STEPS]\n","\n","\n","# Define image\n","img = np.ndarray((3, img_width))\n","img = img[:, :max_width]\n","\n","# Set category color\n","ex_color = ex_samples\n","color_dict = dict(enumerate(list(set(ex_color))))\n","color_dict = {v:k for k,v in color_dict.items()}\n","colors = list(map(lambda x: (color_dict[x] + 1)/len(color_dict.keys()), ex_color))\n","colors = colors[:max_width]\n","img[0,:] = colors\n","\n","# Set ground truth color\n","ground_truth = ground_truth[:max_width]\n","img[1,:] = ground_truth.flatten()\n","\n","# Set prediction color\n","pred = pred[:max_width]\n","img[2,:] = pred\n","\n","# Show the figure\n","plt.figure(4, figsize=(12,8), dpi=100)\n","plt.imshow(img)\n","plt.text(max_width, 0.15, \"Category\")\n","plt.text(max_width, 1.15, \"Ground truth\")\n","plt.text(max_width, 2.15, \"Prediction\")\n","\n","# Index\n","print(\"index index: %i\" % index)\n","\n","h5_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kfBkoxWUibD","executionInfo":{"status":"aborted","timestamp":1613996183437,"user_tz":-60,"elapsed":40491,"user":{"displayName":"SEPEHR NOORZADEH","photoUrl":"","userId":"10646672872241775656"}}},"source":[""],"execution_count":null,"outputs":[]}]}